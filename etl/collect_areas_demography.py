#!/usr/bin/env python3
"""
InvestMTL - Collecte des aires de diffusion et donn√©es d√©mographiques
=================================================================

Ce script t√©l√©charge et traite automatiquement :
- Aires de diffusion 2021 de Statistique Canada (g√©om√©trie)
- Profil du recensement 2021 (donn√©es d√©mographiques)  
- Limite administrative de Montr√©al
- Filtre pour l'√éle de Montr√©al uniquement
- Sauvegarde en GeoJSON et Parquet optimis√©s

Optimis√© pour GitHub Actions, ex√©cution < 1 min
"""

import logging
import zipfile
import tempfile
from pathlib import Path
from typing import Tuple, Dict, Any
import json

import requests
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point, Polygon


# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


# URLs des sources de donn√©es
DATA_SOURCES = {
    'dissemination_areas_shp': 'https://www12.statcan.gc.ca/census-recensement/2021/geo/bound-limit/files/fra/lda_000b21a_f.zip',
    'census_profile_api': 'https://www12.statcan.gc.ca/wds/rest/getFullTableDownloadCSV/F/34100488',
    # URL alternative pour les limites de Montr√©al - utilisons les donn√©es de Statistique Canada
    'montreal_boundaries': 'https://www12.statcan.gc.ca/census-recensement/2021/geo/bound-limit/files/fra/lda_000b21a_f.zip'  # On utilisera le m√™me fichier pour filtrer par le nom
}


def setup_directories() -> Path:
    """Cr√©er la structure de r√©pertoires n√©cessaire."""
    base_dir = Path(__file__).parent.parent
    curated_dir = base_dir / 'data' / 'curated'
    curated_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"üìÅ R√©pertoire de sortie: {curated_dir}")
    return curated_dir


def download_file(url: str, description: str) -> bytes:
    """T√©l√©charger un fichier avec gestion d'erreurs."""
    logger.info(f"‚¨áÔ∏è  T√©l√©chargement {description}...")
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        size_mb = len(response.content) / (1024 * 1024)
        logger.info(f"‚úÖ {description} t√©l√©charg√© ({size_mb:.1f} MB)")
        
        return response.content
        
    except requests.RequestException as e:
        logger.error(f"‚ùå Erreur t√©l√©chargement {description}: {e}")
        raise


def extract_shapefile(zip_content: bytes, temp_dir: Path) -> Path:
    """Extraire le shapefile depuis l'archive ZIP de StatCan."""
    logger.info("üì¶ Extraction de l'archive ZIP...")
    
    zip_path = temp_dir / "dissemination_areas.zip"
    with open(zip_path, 'wb') as f:
        f.write(zip_content)
    
    extract_dir = temp_dir / "extracted"
    extract_dir.mkdir(exist_ok=True)
    
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    
    # Trouver le fichier .shp principal
    shp_files = list(extract_dir.glob("**/*.shp"))
    if not shp_files:
        raise FileNotFoundError("Aucun fichier .shp trouv√© dans l'archive")
    
    shp_path = shp_files[0]
    logger.info(f"‚úÖ Shapefile extrait: {shp_path.name}")
    
    return shp_path


def load_montreal_boundary_from_das(das_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """Cr√©er la limite de Montr√©al √† partir des aires de diffusion de Montr√©al."""
    logger.info("üó∫Ô∏è  Identification des aires de diffusion de Montr√©al...")
    
    # Filtrer les DA qui contiennent "Montr√©al" dans leur nom ou code r√©gional
    # Les codes CMA/RMR pour Montr√©al sont g√©n√©ralement 24462
    montreal_filter = (
        das_gdf['CMANAME'].str.contains('Montr√©al', case=False, na=False) |
        das_gdf['CMAUID'].str.startswith('462', na=False) |  # Code RMR Montr√©al
        das_gdf['PRNAME'].str.contains('Qu√©bec', case=False, na=False)
    )
    
    montreal_das = das_gdf[montreal_filter].copy()
    
    if len(montreal_das) == 0:
        # Fallback: utiliser les coordonn√©es approximatives de Montr√©al
        logger.info("‚ö†Ô∏è  Fallback: filtrage par coordonn√©es g√©ographiques")
        montreal_bounds = (-74.5, 45.2, -73.2, 46.0)  # West, South, East, North
        montreal_das = das_gdf.cx[montreal_bounds[0]:montreal_bounds[2], montreal_bounds[1]:montreal_bounds[3]].copy()
    
    logger.info(f"‚úÖ {len(montreal_das)} aires de diffusion identifi√©es pour Montr√©al")
    
    return montreal_das


def load_and_filter_dissemination_areas(shp_path: Path) -> gpd.GeoDataFrame:
    """Charger les aires de diffusion et filtrer pour Montr√©al."""
    logger.info("üìä Chargement des aires de diffusion...")
    
    # Charger le shapefile avec pyogrio si disponible, sinon fiona
    try:
        das_gdf = gpd.read_file(shp_path, engine='pyogrio')
        logger.info("‚úÖ Utilis√© pyogrio pour charger le shapefile")
    except ImportError:
        das_gdf = gpd.read_file(shp_path)
        logger.info("‚úÖ Utilis√© fiona pour charger le shapefile")
    
    logger.info(f"üìà {len(das_gdf)} aires de diffusion charg√©es")
    
    # S'assurer du bon CRS
    if das_gdf.crs is None:
        das_gdf.set_crs('EPSG:4326', inplace=True)
    elif das_gdf.crs != 'EPSG:4326':
        das_gdf = das_gdf.to_crs('EPSG:4326')
    
    # Filtrer pour Montr√©al
    montreal_das = load_montreal_boundary_from_das(das_gdf)
    
    return montreal_das


def get_census_data_url(api_url: str) -> str:
    """R√©cup√©rer l'URL de t√©l√©chargement CSV depuis l'API StatCan."""
    logger.info("üîó R√©cup√©ration de l'URL des donn√©es de recensement...")
    
    response = requests.get(api_url, timeout=30)
    response.raise_for_status()
    
    # L'API retourne directement l'URL de t√©l√©chargement
    csv_url = response.text.strip()
    if not csv_url.startswith('http'):
        raise ValueError(f"URL invalide retourn√©e par l'API: {csv_url}")
    
    logger.info("‚úÖ URL de t√©l√©chargement CSV obtenue")
    return csv_url


def load_and_filter_census_data(csv_url: str, montreal_da_codes: set) -> pd.DataFrame:
    """T√©l√©charger et filtrer les donn√©es de recensement."""
    logger.info("üìà T√©l√©chargement des donn√©es de recensement...")
    
    # T√©l√©chargement direct avec pandas
    census_df = pd.read_csv(csv_url, low_memory=False)
    logger.info(f"üìä {len(census_df)} lignes de donn√©es de recensement charg√©es")
    
    # Filtrer pour les DA de Montr√©al
    if 'GEO_CODE (POR)' in census_df.columns:
        geo_code_col = 'GEO_CODE (POR)'
    elif 'DGUID' in census_df.columns:
        # Extraire le code g√©ographique du DGUID si n√©cessaire
        geo_code_col = 'DGUID'
    else:
        # Chercher une colonne qui pourrait contenir les codes g√©ographiques
        geo_cols = [col for col in census_df.columns if 'GEO' in col.upper() or 'CODE' in col.upper()]
        if geo_cols:
            geo_code_col = geo_cols[0]
            logger.info(f"‚ö†Ô∏è  Utilisation de la colonne {geo_code_col} pour les codes g√©ographiques")
        else:
            raise ValueError("Impossible de trouver la colonne des codes g√©ographiques")
    
    # Filtrage
    montreal_census = census_df[census_df[geo_code_col].astype(str).isin(montreal_da_codes)]
    
    logger.info(f"‚úÖ {len(montreal_census)} lignes filtr√©es pour Montr√©al")
    
    # Nettoyage et renommage des colonnes importantes
    column_mapping = {}
    for col in montreal_census.columns:
        col_lower = col.lower()
        if 'population' in col_lower and 'total' in col_lower:
            column_mapping[col] = 'population'
        elif 'household' in col_lower and 'total' in col_lower:
            column_mapping[col] = 'households'
        elif 'income' in col_lower and 'median' in col_lower:
            column_mapping[col] = 'median_income'
        elif ('0' in col and '14' in col) or ('youth' in col_lower):
            column_mapping[col] = 'youth_share'
        elif ('65' in col and 'over' in col) or ('senior' in col_lower):
            column_mapping[col] = 'senior_share'
    
    if column_mapping:
        montreal_census = montreal_census.rename(columns=column_mapping)
        logger.info(f"üè∑Ô∏è  Colonnes renomm√©es: {list(column_mapping.values())}")
    
    return montreal_census


def save_outputs(montreal_das: gpd.GeoDataFrame, census_data: pd.DataFrame, output_dir: Path) -> None:
    """Sauvegarder les fichiers de sortie."""
    logger.info("üíæ Sauvegarde des fichiers de sortie...")
    
    # Sauvegarde GeoJSON des aires de diffusion
    areas_path = output_dir / 'areas.geojson'
    montreal_das.to_file(areas_path, driver='GeoJSON')
    logger.info(f"‚úÖ Aires de diffusion sauv√©es: {areas_path}")
    
    # Sauvegarde Parquet des donn√©es d√©mographiques
    demo_path = output_dir / 'demography.parquet'
    census_data.to_parquet(demo_path, index=False, engine='pyarrow')
    logger.info(f"‚úÖ Donn√©es d√©mographiques sauv√©es: {demo_path}")
    
    # Statistiques de sortie
    areas_size = areas_path.stat().st_size / (1024 * 1024)
    demo_size = demo_path.stat().st_size / (1024 * 1024)
    
    logger.info(f"üìä Fichiers g√©n√©r√©s:")
    logger.info(f"   ‚Ä¢ areas.geojson: {areas_size:.1f} MB ({len(montreal_das)} aires)")
    logger.info(f"   ‚Ä¢ demography.parquet: {demo_size:.1f} MB ({len(census_data)} lignes)")


def main() -> None:
    """Fonction principale d'ex√©cution."""
    logger.info("üöÄ D√©but de la collecte des donn√©es Montr√©al")
    logger.info("=" * 60)
    
    try:
        # Configuration
        output_dir = setup_directories()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # 1. T√©l√©chargement et extraction des aires de diffusion
            das_zip = download_file(
                DATA_SOURCES['dissemination_areas_shp'], 
                "aires de diffusion 2021"
            )
            shp_path = extract_shapefile(das_zip, temp_path)
            
            # 2. Filtrage des aires de diffusion pour Montr√©al (int√©gr√© dans la fonction)
            montreal_das = load_and_filter_dissemination_areas(shp_path)
            
            # 3. Pr√©paration des codes g√©ographiques pour le filtrage du recensement
            da_codes = set(montreal_das['DAUID'].astype(str))  # DAUID = code unique des aires de diffusion
            
            # 4. T√©l√©chargement des donn√©es de recensement
            csv_url = get_census_data_url(DATA_SOURCES['census_profile_api'])
            census_data = load_and_filter_census_data(csv_url, da_codes)
            
            # 5. Sauvegarde des r√©sultats
            save_outputs(montreal_das, census_data, output_dir)
        
        logger.info("=" * 60)
        logger.info("‚úÖ Collecte termin√©e avec succ√®s!")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur durant la collecte: {e}")
        raise


if __name__ == "__main__":
    main()
